{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n49UaWPGAd"
      },
      "source": [
        "Experimental Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvOkHAkDghww",
        "outputId": "9d30f5df-ab03-4535-cb30-c4bb48c4d19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install the OpenAI Python package.\n",
        "%pip install openai\n",
        "%pip install -U langchain-community\n",
        "%pip install tiktoken\n",
        "%pip install faiss-gpu\n",
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import gspread\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from IPython.display import display\n",
        "from google.oauth2.service_account import Credentials\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "from langchain.llms import OpenAI as LangchainOpenAI\n",
        "\n",
        "# read data frame function\n",
        "def read_data_frame(document_id, sheet_name):\n",
        "    export_link = f\"https://docs.google.com/spreadsheets/d/{document_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "    return  pd.read_csv(export_link)\n",
        "\n",
        "#define scope for google sheet API\n",
        "scopes = [\n",
        "    'https://www.googleapis.com/auth/spreadsheets',\n",
        "    'https://www.googleapis.com/auth/drive'\n",
        "]\n",
        "\n",
        "# Initiate OpenAI\n",
        "client = OpenAI(\n",
        "    base_url='https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/',\n",
        "    api_key='a0BIj000001rjZ8MAI'\n",
        ")\n",
        "\n",
        "# Credential login\n",
        "credentials = Credentials.from_service_account_info(\n",
        "        {\n",
        "          \"type\": \"service_account\",\n",
        "          \"project_id\": \"elegant-tangent-440815-a4\",\n",
        "          \"private_key_id\": \"caa92219e24a863de081d21583359f2fd021480c\",\n",
        "          \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCZ3+3CM4PmmLYd\\nNrIJcN1cnsZrDkl5Ah2wC4yMwKMfnirMTiVY1TYfgTj4RYRiP+fCMfPHX0SlykV0\\n0XVA6HTgmmFohAg6M3BoAnHS0cbOBSDn2gpGLmDujwmLI2vlj539G+kuC/XPeRqN\\nK/omOZ3cFhRj3Q659eOx55SWYiJ54KnRA8FSM+HrYJgMUkr4E/3xg4JLKRecJ0uu\\nYt09vNxU1/wVlBwhIhjAdbtGf1yrfFEwOJkwMjNRdGCElEOg4aRJVHuU96kZsntx\\nFqkyqIqTU2g3iC9VYwBdOdmALvdmYZTHDqGT0ug25Ej893/4iHC6Fpvgygxgct88\\n1B2QbDv5AgMBAAECggEAPzjZaHRgGmveT4x8hBKCcR6vaacaGwT6i62DFwXDQCdt\\ncDofcCtSLImcja2KYg/dulVp0x3ah7/e38t7wKqB8xKbOSUeeENQSPvQJo2YgGdt\\nCLX2iLVfkETm5+sq1sw2XpuMKCYz3gXlGeHayr/bk2TjBdD6zv8viZYb39n8TlSU\\neAHv8/QGoPUKCvG+uLHqi45/zhbGInwHxuWu4BWoC/Jfs/OSgDeM5VC/B4mVkag/\\n1tBkw8J+qsDCJBoGD2kKfEMW9xTW6K/yqEvrNRTjTEOIaYtLP+KKkSEJq6USGCLY\\n1kOpOhAMmwOklGbm7dTl1mDrNpUBQOePpNUVQoTFzQKBgQDHyEWAXIQWt/vs1Um/\\nOMaXmsSVy8oZQzU3/Z1osGVggKhj7EY8Az4ft9YiZvYQP/05UgGmaJYIEAbQTTf3\\no3yKveCAyoXHv2oPHD3gS3Po4Jz0KGBsNM5ortfK+Uykvg2EncPvi2HKCcf51CGf\\nQ1PttVsBHBCU8DEeWInlwTLKhwKBgQDFLJwkcG8mG88e6ubf5pR5I7rVEPVnlHzQ\\nE3rkgF5upWqDhKWJc4VxF3ogRZcSy2gcEdFDdMzLToPs3XfxM5qbcrNLnBljMmHy\\nWhbcpkokjbZcgljg2FPrmrAaZ4W3QrdT8kwnpiT6XK6jX62Gr9NhSMwOTfVpMpXj\\nCa8shznlfwKBgQCB+vP1Grw5x8RZhz9u8TKMCn7icu9vVkG2xwP1y+Z5TdvA/0WG\\n4Bk4K7RfN5vaYLeQ5qD6MsuCPWMhfUvvi2eJIRaC1MELf6cyY46CcrTcC98yH170\\np7qvcyok/eP2v0wuPzLulEGwYILCMVkatIRTgQ3PgAHt1QQwGSzG1dcE2wKBgDIK\\nvWI+Kud4HVwScCAZTEtmdw+Ga1IrjHXey8zci5r3Xo4ch0rYR+DI/ZTdNJdvim+9\\nUegV57gdqDvghYVw/GdBeCHTb1oOum8g0DaV+bFHSiY2aso9/SaJrvI0nepCA3dJ\\nwmw5rZ7hEO2j5c2OKE7DhA6JWKSnUwU5Ov1JILePAoGAZyza69XfYDTT1z+IDAm4\\nIjTeKUqXw90e+/IH8nGViBdEyOd9eMsxlxdlPkloFlerarLwNETpzQbtaZpew+NA\\nA/JUOKQvsRJyzO2RnEY9hKtVo1QErL7polzSWanjHZtKgDDZleEmi8q90sd8M+DX\\nJzjFu4A18Xf0Mfppb4P7ff4=\\n-----END PRIVATE KEY-----\\n\",\n",
        "          \"client_email\": \"abcd-398@elegant-tangent-440815-a4.iam.gserviceaccount.com\",\n",
        "          \"client_id\": \"108970581876850051486\",\n",
        "          \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "          \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "          \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "          \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/abcd-398%40elegant-tangent-440815-a4.iam.gserviceaccount.com\",\n",
        "          \"universe_domain\": \"googleapis.com\"\n",
        "        }\n",
        ", scopes=scopes\n",
        ")\n",
        "\n",
        "gc = gspread.authorize(credentials) #Authorize\n",
        "document_id = '14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U'\n",
        "spreadsheet = gc.open_by_key(\"1ehZxkO3ENDOfkTHzc4II5eJAQ0GFjS-GQxuwQ3VGTRw\") # Open document by Doc Id\n",
        "products_df = read_data_frame(document_id, 'products') #get Products\n",
        "emails_df = read_data_frame(document_id, 'emails') #Get emails\n",
        "\n",
        "# Email classification function\n",
        "def classify_email(email_subject, email_body):\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"\n",
        "            You are an AI assistant helping a fashion store classify emails.\n",
        "            Your task is to STRICTLY classify the following email as either \"product inquiry\" or \"order request\", based on the content of the email. DO NOT generate any other text.\n",
        "            Example 1:\n",
        "            Subject: Question about Winter Coats\n",
        "            Body: Hello, I'm interested in your winter coats. What materials are they made from?\n",
        "            Classification: product inquiry\n",
        "\n",
        "            Example 2:\n",
        "            Subject: Order for T-shirts\n",
        "            Body: I'd like to order 3 of the blue T-shirts (SKU: TS003).\n",
        "            Classification: order request\n",
        "\n",
        "            Example 3:\n",
        "            Subject: You Know\n",
        "            Body: Hi there I want to place an order for that popular item you sell. The one that's been selling like hotcakes lately. You know what I mean right?\n",
        "            Classification: product inquiry\n",
        "\n",
        "            Notes :\n",
        "            - In case of vagueness, default to 'product inquiry' since we should make order request only for person that express clear intent.\n",
        "\n",
        "            Now classify this email:\n",
        "            Subject: {email_subject}\n",
        "            Body: {email_body}\n",
        "            \"\"\"}\n",
        "        ],\n",
        "        temperature=0.1, # focussing the LLM\n",
        "        top_p=0.5 #enhancing probability\n",
        "    )\n",
        "  return response.choices[0].message.content.strip()\n",
        "\n",
        "classification_results = []\n",
        "\n",
        "# Build Classification data frame\n",
        "for index, row in emails_df.iterrows():\n",
        "  email_id = row['email_id']\n",
        "  subject = row['subject']\n",
        "  body = row['message']\n",
        "  category = classify_email(subject, body)\n",
        "  classification_results.append([email_id, category])\n",
        "\n",
        "classification_df = pd.DataFrame(classification_results, columns=['email ID', 'category'])\n",
        "\n",
        "#Add Spreadsheet\n",
        "try:\n",
        "  classification_sheet = spreadsheet.add_worksheet(title=\"email-classification\", rows=100, cols=10)\n",
        "except gspread.exceptions.APIError as e:\n",
        "  if \"already exists\" in str(e):\n",
        "    classification_sheet = spreadsheet.worksheet(\"email-classification\")\n",
        "  else:\n",
        "    raise e\n",
        "\n",
        "# Write DataFrame into Spreadsheet\n",
        "classification_sheet.update(range_name='A1', values=[classification_df.columns.values.tolist()] + classification_df.values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSnFmuQyKHD",
        "outputId": "63940953-29b3-4921-fe3a-6bfc546d9b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1ehZxkO3ENDOfkTHzc4II5eJAQ0GFjS-GQxuwQ3VGTRw',\n",
              " 'updatedRange': \"'email-classification'!A1:B22\",\n",
              " 'updatedRows': 22,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedCells': 44}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm3ZeatjYjM3"
      },
      "source": [
        "Process order requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_requests = classification_df[classification_df['category'] == 'order request']\n",
        "\n",
        "def extract_order_details(email_body):\n",
        "  \"\"\"Extracts product IDs and quantities from an order request email.\"\"\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-4o\",\n",
        "       messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "        Extract the product IDs and quantities from this order request email.\n",
        "\n",
        "        Important:\n",
        "        * The email might contain product names or product IDs with spaces or slight variations.\n",
        "        * All valid product IDs consist of 4 letters followed by 4 numbers, without any spaces.\n",
        "        * If you find a product name or an ID with spaces,\n",
        "           first convert it to the correct format (e.g., \"CBT 89 01\" should become \"CBT8901\")\n",
        "           and then use the corresponding product ID from the catalog.\n",
        "\n",
        "        Product Catalog:\n",
        "        {products_df[['product_id', 'name']].to_json(orient='records')}\n",
        "\n",
        "        If no quantity is specified, assume a default quantity of 1.\n",
        "        If the quantity is expressed as \"all remaining items in stock\", set the quantity to -1.\n",
        "\n",
        "        If no product IDs or quantities can be found after careful analysis and conversion to the correct format,\n",
        "        include \"product_id\" and \"quantity\" keys in the JSON with values set to \"not found\".\n",
        "\n",
        "        Return the data in a JSON format with \"product_id\" and \"quantity\" as keys.\n",
        "\n",
        "        Email Body: {email_body}\n",
        "        \"\"\"}\n",
        "    ]\n",
        "  )\n",
        "  try:\n",
        "      # Extract the JSON string by removing the triple backticks and the \"json\" keyword\n",
        "      json_string = response.choices[0].message.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "      order_details = json.loads(json_string)\n",
        "      return order_details\n",
        "  except json.JSONDecodeError:\n",
        "      print(f\"Error decoding JSON: {response.choices[0].message.content.strip()}\")\n",
        "      return None\n",
        "\n",
        "def process_order(email_id, order_details):\n",
        "  \"\"\"Processes an order request, updates stock, and returns order status.\"\"\"\n",
        "  order_status = []\n",
        "  if isinstance(order_details, dict):\n",
        "    order_details = [order_details]\n",
        "  for item in order_details:\n",
        "    product_id = item['product_id']\n",
        "    quantity = item['quantity']\n",
        "\n",
        "    # Find the product in the product catalog\n",
        "    product = products_df[products_df['product_id'] == product_id].iloc[0]\n",
        "\n",
        "    if quantity == -1:\n",
        "            quantity = int(product['stock'])\n",
        "\n",
        "    # Check stock and update\n",
        "    if int(product['stock']) >= quantity:\n",
        "      products_df.loc[products_df['product_id'] == product_id, 'stock'] = int(product['stock']) - quantity\n",
        "      status = \"created\"\n",
        "    else:\n",
        "      status = \"out of stock\"\n",
        "    order_status.append([email_id, product_id, quantity, status])\n",
        "  return order_status\n",
        "\n",
        "def generate_order_response(email_id, order_status, email_body):\n",
        "  \"\"\"Generates an email response based on the order processing results.\"\"\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"\"\"\n",
        "          Task: Generate a professional email response for an order.\n",
        "\n",
        "          Order details:\n",
        "          - Email ID: {email_id}\n",
        "          - Order status: {order_status}\n",
        "          - Customer email body: {email_body}\n",
        "\n",
        "          Instructions:\n",
        "          - If the order is successful, thank the customer and provide a summary of the order.\n",
        "          - If any items are out of stock, apologize, explain the situation, and suggest alternatives if available.\n",
        "          - Maintain a professional and helpful tone.\n",
        "          \"\"\"}\n",
        "      ]\n",
        "  )\n",
        "  return response.choices[0].message.content.strip()\n",
        "\n",
        "order_results = []\n",
        "order_responses = []\n",
        "\n",
        "for index, row in order_requests.iterrows():\n",
        "  email_id = row['email ID']\n",
        "  email_body = emails_df[emails_df['email_id'] == email_id]['message'].values[0]\n",
        "  order_details = extract_order_details(email_body)\n",
        "  if order_details:\n",
        "    order_status = process_order(email_id, order_details)\n",
        "    order_results.extend(order_status)  # Accumulate order status\n",
        "    response_email = generate_order_response(email_id, order_status, email_body)\n",
        "    order_responses.append([email_id, response_email])\n",
        "\n",
        "# Create DataFrames for the results\n",
        "order_status_df = pd.DataFrame(order_results, columns=['email ID', 'product ID', 'quantity', 'status'])\n",
        "order_response_df = pd.DataFrame(order_responses, columns=['email ID', 'response'])\n",
        "\n",
        "# Create new worksheets for order results\n",
        "try:\n",
        "    order_status_sheet = spreadsheet.add_worksheet(title=\"order-status\", rows=100, cols=10)\n",
        "except gspread.exceptions.APIError as e:\n",
        "    if \"already exists\" in str(e):\n",
        "        order_status_sheet = spreadsheet.worksheet(\"order-status\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "try:\n",
        "    order_response_sheet = spreadsheet.add_worksheet(title=\"order-response\", rows=100, cols=10)\n",
        "except gspread.exceptions.APIError as e:\n",
        "    if \"already exists\" in str(e):\n",
        "        order_response_sheet = spreadsheet.worksheet(\"order-response\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "# Write the DataFrames to the worksheets\n",
        "order_status_sheet.update(range_name='A1', values=[order_status_df.columns.values.tolist()] + order_status_df.values.tolist())\n",
        "order_response_sheet.update(range_name='A1', values=[order_response_df.columns.values.tolist()] + order_response_df.values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPk2T-wvD6kr",
        "outputId": "e280c2b0-8ff4-4462-d597-06f47ddd6cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1ehZxkO3ENDOfkTHzc4II5eJAQ0GFjS-GQxuwQ3VGTRw',\n",
              " 'updatedRange': \"'order-response'!A1:B9\",\n",
              " 'updatedRows': 9,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedCells': 18}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ExT_MQRhos"
      },
      "source": [
        "Handle product inquiry"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi OpenAI embeddings\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_key=client.api_key,\n",
        "    base_url=str(client.base_url)\n",
        ")\n",
        "\n",
        "# Create FAISS vector store from Product\n",
        "product_docs = [\n",
        "    Document(\n",
        "        page_content=row['description'],  # This is the product description\n",
        "        metadata={\"product_id\": row['product_id']}  # This is additional metadata (product_id)\n",
        "    )\n",
        "    for _, row in products_df.iterrows()\n",
        "]\n",
        "vectorstore = FAISS.from_documents(product_docs, embeddings)\n",
        "\n",
        "# LLM function\n",
        "def create_llm():\n",
        "  \"\"\"\n",
        "  Create LLM instance using existing OpenAI Client.\n",
        "  \"\"\"\n",
        "  return client\n",
        "\n",
        "# Initiate RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=LangchainOpenAI(temperature=0, openai_api_key=client.api_key,base_url=str(client.base_url)),  # Add openai_api_key\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever()\n",
        ")\n",
        "\n",
        "def handle_product_inquiry(email_body):\n",
        "    \"\"\"Generates a response to a product inquiry email.\"\"\"\n",
        "    result = qa_chain({\"query\": email_body})\n",
        "    return result['result']\n",
        "\n",
        "# Filter email \"product inquiry\"\n",
        "product_inquiries = classification_df[classification_df['category'] == 'product inquiry']\n",
        "\n",
        "inquiry_responses = []\n",
        "for index, row in product_inquiries.iterrows():\n",
        "    email_id = row['email ID']\n",
        "    email_body = emails_df[emails_df['email_id'] == email_id]['message'].values[0]\n",
        "    response_email = handle_product_inquiry(email_body)\n",
        "    inquiry_responses.append([email_id, response_email])\n",
        "\n",
        "# Create DataFrame to response inquiry\n",
        "inquiry_response_df = pd.DataFrame(inquiry_responses, columns=['email ID', 'response'])\n",
        "\n",
        "# Create worksheet to respons inquiry\n",
        "try:\n",
        "    inquiry_response_sheet = spreadsheet.add_worksheet(title=\"inquiry-response\", rows=100, cols=10)\n",
        "except gspread.exceptions.APIError as e:\n",
        "    if \"already exists\" in str(e):\n",
        "        inquiry_response_sheet = spreadsheet.worksheet(\"inquiry-response\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "# Write DataFrame to worksheet\n",
        "inquiry_response_sheet.update(range_name='A1', values=[inquiry_response_df.columns.values.tolist()] + inquiry_response_df.values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FqhhLr9HfML",
        "outputId": "1b9dc012-20ac-42ea-8eac-c12f4697c0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1ehZxkO3ENDOfkTHzc4II5eJAQ0GFjS-GQxuwQ3VGTRw',\n",
              " 'updatedRange': \"'inquiry-response'!A1:B14\",\n",
              " 'updatedRows': 14,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedCells': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}